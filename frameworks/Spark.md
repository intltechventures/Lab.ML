
Apache Spark Machine Learning Resources
====

### References
* http://spark.apache.org/
  * https://spark.apache.org/downloads.html
  * https://spark.apache.org/docs/latest/
  * https://spark.apache.org/examples.html
* https://github.com/apache/spark
* https://spark.apache.org/mllib/
  * "MLlib fits into Spark's APIs and interoperates with NumPy in Python (as of Spark 0.9) and R libraries (as of Spark 1.5). You can use any Hadoop data source (e.g. HDFS, HBase, or local files), making it easy to plug into Hadoop workflows."
  * "100x faster than MapReduce"
  * Algorithms included:
    * Classification: logistic regression, naive Bayes,...
    * Regression: generalized linear regression, survival regression,...
    * Decision trees, random forests, and gradient-boosted trees
    * Recommendation: alternating least squares (ALS)
    * Clustering: K-means, Gaussian mixtures (GMMs),...
    * Topic modeling: latent Dirichlet allocation (LDA)
    * Frequent itemsets, association rules, and sequential pattern mining



### Interesting Spark News
* 2018
  * https://spark.apache.org/releases/spark-release-2-4-0.html
* 2016
  * https://www.infoq.com/news/2016/05/Apache-Spark-2.0-Tech-Preview
  * http://go.databricks.com/how-edmunds-leverages-apache-spark-on-databricks-to-improve-customer-conversion
    * "Apache Spark 2.4.0 is the fifth release in the 2.x line. This release adds Barrier Execution Mode for better integration with deep learning frameworks, introduces 30+ built-in and higher-order functions to deal with complex data type easier, improves the K8s integration, along with experimental Scala 2.12 support. Other major updates include the built-in Avro data source, Image data source, flexible streaming sinks, elimination of the 2GB block size limitation during transfer, Pandas UDF improvements. In addition, this release continues to focus on usability, stability, and polish while resolving around 1100 tickets."

