
Apache Spark Machine Learning Resources
====

### References
* http://spark.apache.org/
* https://github.com/apache/spark
* https://spark.apache.org/mllib/
  * "MLlib fits into Spark's APIs and interoperates with NumPy in Python (as of Spark 0.9) and R libraries (as of Spark 1.5). You can use any Hadoop data source (e.g. HDFS, HBase, or local files), making it easy to plug into Hadoop workflows."
  * "100x faster than MapReduce"
  * Algorithms included:
    * Classification: logistic regression, naive Bayes,...
    * Regression: generalized linear regression, survival regression,...
    * Decision trees, random forests, and gradient-boosted trees
    * Recommendation: alternating least squares (ALS)
    * Clustering: K-means, Gaussian mixtures (GMMs),...
    * Topic modeling: latent Dirichlet allocation (LDA)
    * Frequent itemsets, association rules, and sequential pattern mining



### Interesting Spark News
* https://www.infoq.com/news/2016/05/Apache-Spark-2.0-Tech-Preview
* http://go.databricks.com/how-edmunds-leverages-apache-spark-on-databricks-to-improve-customer-conversion

