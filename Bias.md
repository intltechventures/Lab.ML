
Machine Learning Bias Research/Resources
====




### Books
* Algorithms of Oppression: How Search Engines Reinforce Racism](https://www.amazon.com/Algorithms-Oppression-Search-Engines-Reinforce/dp/1479837245)



### News
* 2019
  * [2019-01-23 An MIT researcher who analyzed facial recognition software found eliminating bias in AI is a matter of priorities](https://www.businessinsider.com/biases-ethics-facial-recognition-ai-mit-joy-buolamwini-2019-1)
    * https://www.ajlunited.org/
    * https://www.nytimes.com/2018/06/21/opinion/facial-analysis-technology-bias.html

  * [NPR NewsHour: Artificial intelligence can be biased against certain people (video)](https://twitter.com/NewsHour/status/1098230794877689856)


* 2018
  * [2018-09-06 IBM Used NYPD Surveillance Footage to Develop Technology That Lets Police Search by Skin Color](https://theintercept.com/2018/09/06/nypd-surveillance-camera-skin-tone-search/)



### Researchers
* Ball, Patrick
  * Human Rights Data Analysis Group (HRDAG)
  * https://hrdag.org/
  * https://twitter.com/vm_wylbur

* Gohdes, Anita
  * Professor, The Hertie Schoool
    * https://www.hertie-school.org/
    * https://twitter.com/thehertieschool
  * http://www.anitagohdes.net/
  * https://twitter.com/ARGohdes

* Lum, Kristian,  PhD
  * Lead Statistician at the Human Rights Data Analysis Group (HRDAG)
    * https://hrdag.org/people/kristian-lum-phd/
    * "Kristianâ€™s research primarily focuses on examining the uses of machine learning in the criminal justice system and has concretely demonstrated the potential for machine learning-based predictive policing models to reinforce and, in some cases, amplify historical racial biases in law enforcement"
  * https://twitter.com/KLdivergence

* Venkatasubramanian, Suresh, PhD
  * School of Computing, University of Utah
  * https://algorithmicfairness.wordpress.com/
  * https://twitter.com/geomblog



### Organizations
* Human Rights Data Analysis Group
  * https://hrdag.org/
  * https://twitter.com/hrdag



