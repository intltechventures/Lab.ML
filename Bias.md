
Machine Learning Bias Research/Resources
====




### Books
* Algorithms of Oppression: How Search Engines Reinforce Racism](https://www.amazon.com/Algorithms-Oppression-Search-Engines-Reinforce/dp/1479837245)



### News
* 2019
  * [2019-01-23 An MIT researcher who analyzed facial recognition software found eliminating bias in AI is a matter of priorities](https://www.businessinsider.com/biases-ethics-facial-recognition-ai-mit-joy-buolamwini-2019-1)
    * https://www.ajlunited.org/
    * https://www.nytimes.com/2018/06/21/opinion/facial-analysis-technology-bias.html

  * [NPR NewsHour: Artificial intelligence can be biased against certain people (video)](https://twitter.com/NewsHour/status/1098230794877689856)


* 2018
  * [2018-09-06 IBM Used NYPD Surveillance Footage to Develop Technology That Lets Police Search by Skin Color](https://theintercept.com/2018/09/06/nypd-surveillance-camera-skin-tone-search/)



### Researchers
* Ball, Patrick
  * Human Rights Data Analysis Group (HRDAG)
  * https://hrdag.org/
  * https://twitter.com/vm_wylbur

* Gohdes, Anita
  * Professor, The Hertie Schoool
    * https://www.hertie-school.org/
    * https://twitter.com/thehertieschool
  * http://www.anitagohdes.net/
  * https://twitter.com/ARGohdes

* Lum, Kristian,  PhD
  * Lead Statistician at the Human Rights Data Analysis Group (HRDAG)
    * https://hrdag.org/people/kristian-lum-phd/
    * "Kristianâ€™s research primarily focuses on examining the uses of machine learning in the criminal justice system and has concretely demonstrated the potential for machine learning-based predictive policing models to reinforce and, in some cases, amplify historical racial biases in law enforcement"
  * https://twitter.com/KLdivergence

* Venkatasubramanian, Suresh, PhD
  * School of Computing, University of Utah
  * https://algorithmicfairness.wordpress.com/
  * https://twitter.com/geomblog

* Vishnoi, Nisheeth
  * Professor of CS@Yale 
  * http://www.cs.yale.edu/homes/vishnoi/Home.html
  * https://twitter.com/NisheethVishnoi


### Organizations
* Human Rights Data Analysis Group
  * https://hrdag.org/
  * https://twitter.com/hrdag
* Safety & Justice Challenge
  * http://www.safetyandjusticechallenge.org/
  * https://twitter.com/safety_justice



### Articles to read, assess, sort, select
* https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
  * https://www.documentcloud.org/documents/2840784-Practitioner-s-Guide-to-COMPAS-Core.html#document/p30/a296482
  * https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say
  * https://www.propublica.org/article/propublica-responds-to-companys-critique-of-machine-bias-story
  * https://www.propublica.org/article/technical-response-to-northpointe
  * https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm

* https://medium.com/thoughts-and-reflections/racial-bias-and-gender-bias-examples-in-ai-systems-7211e4c166a1

* 1Algorithms, Platforms, and Ethnic Bias: An Integrative Essay
  * https://kenney.faculty.ucdavis.edu/wp-content/uploads/sites/332/2018/09/Silva-Kenney-Algorithms-Platforms-and-Bias-9-8-18.pdf

* PreTrial Risk Assessment Tools
  * http://www.safetyandjusticechallenge.org/resource/pretrial-risk-assessment-tools-a-primer-for-judges-prosecutors-and-defense-attorneys/
  * http://www.safetyandjusticechallenge.org/wp-content/uploads/2019/02/Pretrial-Risk-Assessment-Primer-February-2019.pdf

* https://medium.com/mit-media-lab/the-algorithmic-justice-league-3cc4131c5148


