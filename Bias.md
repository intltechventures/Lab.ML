
# Machine Learning Bias Research/Resources


## References




## Books
* Algorithms of Oppression: How Search Engines Reinforce Racism](https://www.amazon.com/Algorithms-Oppression-Search-Engines-Reinforce/dp/1479837245)



## Github Resources

- https://github.com/linkedin/LiFT
  + "The LinkedIn Fairness Toolkit (LiFT) is a Scala/Spark library that enables the measurement of fairness in large
    scale machine learning workflows."
  + See 2021 LinkedIn announcement article, below.




## Articles

### 2021

- 2021-05-14 Image classification algorithms at Apple, Google still push racist tropes
  + https://algorithmwatch.org/en/apple-google-computer-vision-racist/

- LinkedIn open-sources toolkit to measure AI model fairness
  + https://venturebeat.com/2020/08/25/linkedin-open-sources-toolkit-to-measure-ai-model-fairness/
    * "designed to enable the measurement of fairness in AI and machine learning workflows. The company says LiFT can be
      deployed during training and scoring to measure biases in training data sets, and to evaluate notions of fairness
      for models while detecting differences in their performance across subgroups."
        

###  2019
  * [2019-01-23 An MIT researcher who analyzed facial recognition software found eliminating bias in AI is a matter of priorities](https://www.businessinsider.com/biases-ethics-facial-recognition-ai-mit-joy-buolamwini-2019-1)
    * https://www.ajlunited.org/
    * https://www.nytimes.com/2018/06/21/opinion/facial-analysis-technology-bias.html

  * [NPR NewsHour: Artificial intelligence can be biased against certain people (video)](https://twitter.com/NewsHour/status/1098230794877689856)


### 2018
  * [2018-09-06 IBM Used NYPD Surveillance Footage to Develop Technology That Lets Police Search by Skin Color](https://theintercept.com/2018/09/06/nypd-surveillance-camera-skin-tone-search/)




## Researchers
* Ball, Patrick
  * Human Rights Data Analysis Group (HRDAG)
  * https://hrdag.org/
  * https://twitter.com/vm_wylbur

* Gohdes, Anita
  * Professor, The Hertie Schoool
    * https://www.hertie-school.org/
    * https://twitter.com/thehertieschool
  * http://www.anitagohdes.net/
  * https://twitter.com/ARGohdes

* Lum, Kristian,  PhD
  * Lead Statistician at the Human Rights Data Analysis Group (HRDAG)
    * https://hrdag.org/people/kristian-lum-phd/
    * "Kristianâ€™s research primarily focuses on examining the uses of machine learning in the criminal justice system and has concretely demonstrated the potential for machine learning-based predictive policing models to reinforce and, in some cases, amplify historical racial biases in law enforcement"
  * https://twitter.com/KLdivergence

* Venkatasubramanian, Suresh, PhD
  * School of Computing, University of Utah
  * https://algorithmicfairness.wordpress.com/
  * https://twitter.com/geomblog

* Vishnoi, Nisheeth
  * Professor of CS@Yale 
  * http://www.cs.yale.edu/homes/vishnoi/Home.html
  * https://twitter.com/NisheethVishnoi


## Organizations
* Human Rights Data Analysis Group
  * https://hrdag.org/
  * https://twitter.com/hrdag
* Safety & Justice Challenge
  * http://www.safetyandjusticechallenge.org/
  * https://twitter.com/safety_justice



## Articles to read, assess, sort, select
* https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
  * https://www.documentcloud.org/documents/2840784-Practitioner-s-Guide-to-COMPAS-Core.html#document/p30/a296482
  * https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say
  * https://www.propublica.org/article/propublica-responds-to-companys-critique-of-machine-bias-story
  * https://www.propublica.org/article/technical-response-to-northpointe
  * https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm

* https://medium.com/thoughts-and-reflections/racial-bias-and-gender-bias-examples-in-ai-systems-7211e4c166a1

* 1Algorithms, Platforms, and Ethnic Bias: An Integrative Essay
  * https://kenney.faculty.ucdavis.edu/wp-content/uploads/sites/332/2018/09/Silva-Kenney-Algorithms-Platforms-and-Bias-9-8-18.pdf

* PreTrial Risk Assessment Tools
  * http://www.safetyandjusticechallenge.org/resource/pretrial-risk-assessment-tools-a-primer-for-judges-prosecutors-and-defense-attorneys/
  * http://www.safetyandjusticechallenge.org/wp-content/uploads/2019/02/Pretrial-Risk-Assessment-Primer-February-2019.pdf

* https://medium.com/mit-media-lab/the-algorithmic-justice-league-3cc4131c5148


